{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Natural language processing in TensorFlow\n",
    "Text is messier than images (short and long sentences). How to represent words and sentences as numbers for learning?\n",
    "Week 1: load text, preprocess it and setup the data so it can be fed to NN.\n",
    "We start by building models to represent text (sentiment in text). It will be trained on a labeled text and then classify a new text based on what they've seen.\n",
    "Pixel values were already numbers, but what happens with text? How can we do a sentiment analysis with words?\n",
    "\n",
    "## Word based encodings\n",
    "We could take character encodings for each character of a set (e.g. ASCII), but would that help us to understand the meaning of the word?\n",
    "```\n",
    "`LISTEN` and `SILENT` - would have the same representation but they mean different things!\n",
    "```\n",
    "\n",
    "What if we give value to each word?\n",
    "```\n",
    "I Love my dog\n",
    "1 2     3  4\n",
    "\n",
    "I Love my cat\n",
    "1 2     3  5\n",
    "\n",
    "Now we can see some similarities in sentences\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "## Using APIs\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer # one of the ways to encode words and transform sentences into vectors\n",
    "\n",
    "sentences = [\n",
    "    'I love my dog',\n",
    "    'I love my cat',\n",
    "    'You love my dog!' # the '!' will be stripped off by tokenizer\n",
    "]\n",
    "\n",
    "# num_words - a total amount of unique distinct words; Tokenizer will take top 100 words by value and encode those\n",
    "# Worth experimenting with. sometimes the impact of less words can be minimal in accuracy but huge in training time. Use with care!\n",
    "# Tokenizer strips punctuation out and lowercases the sentence\n",
    "tokenizer = Tokenizer(num_words=100)\n",
    "tokenizer.fit_on_texts(sentences) # takes the data and encodes it\n",
    "word_index = tokenizer.word_index # returns a dictionary of `word->word_token`\n",
    "print(word_index)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'love': 1, 'my': 2, 'i': 3, 'dog': 4, 'cat': 5, 'you': 6}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}